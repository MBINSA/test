{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d410e39-e0d4-4430-ba0f-fc8c59d620d0",
   "metadata": {},
   "source": [
    "# Code Python - Electre Tri "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c038ddb9",
   "metadata": {},
   "source": [
    "## Introduction to the project\n",
    "\n",
    "The company at the origin of the request is the social landlord 3F, part of the national group Action Logement. Its request concerns the renovation of three of its housing buildings located in the Lyon region. These buildings having been built in the years 2014, the company thus considered necessary to carry out renovation works for the whole of these 3 buildings. \n",
    "\n",
    "The company has found it difficult in the past to find out how to renovate a building in view regarding the different aspects that come into play. For example, when looking at the minimum energy loss between primary and final energy, gas appears to be the most interesting form of energy. However, when looking at the environmental impact of this form of energy, gas is badly ranked. Thus, they wish to take into account several aspects of energy renovation in this project.  \n",
    "\n",
    "Since several options of renovation are possible and the decision is based on multiple criteria, it has been chosen thaht a multi-criteria analysis should be carried out.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c329d900",
   "metadata": {},
   "source": [
    "### Electre Tri as a multi-criteria analysis \n",
    "\n",
    "The Electre Tri method is the multi-criteria analysis that is selected for the project. In its process, the input data for each item is normalised using thresholds and compared to difference profiles that separate categories. This method results in an optimistic and pessimistic ranking of the elements in which every actions are ranked in categories.\n",
    "\n",
    "The following code allows to execute step by step the calculations of the Electre Tri method :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bc9ebed",
   "metadata": {},
   "source": [
    "*expliquer peut être comment fonctionne la méthode vite fait en mode il y a 28 scenarios 16 critères et il faut poids thresholds etc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "cfcdcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random, vstack, empty\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f512a50",
   "metadata": {},
   "source": [
    "### Import of data from csv file as a Pandas Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2d03a3f",
   "metadata": {},
   "source": [
    "The input of the whole analysis is a csv file containing the following informations : \n",
    "- The mean value of the performance of each scenario regarding each criteria \n",
    "- The weight of each criteria \n",
    "- The variance of each criteria\n",
    "- The 5 reference profiles : b0, b1, b2, b3, b4 and b5 \n",
    "- The 3 thresholds : q (the indiference threshold), p (the preference threshold), v (the veto threshold)\n",
    "\n",
    "It is imported as a dataframe `d`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "5f6003b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('Input_data.csv')\n",
    "λ = 0.75"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e703acc6",
   "metadata": {},
   "source": [
    "### Monte Carlo Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "126e492b",
   "metadata": {},
   "source": [
    "Since we study 28 scenarios according to 16 criteria, compute all the possible combinations of performance values would not be feasible. To have more robust results, our hypothesis is to use the Monte Carlo method to obtain data sets from distributions and use those data sets in the Electre Tri procedure. \n",
    "\n",
    "Monte-Carlo simulation is used in complex systems in order to estimate some operations by using random sample and statistical modeling. \n",
    "1. Pick a value from Probability Distribution Functions\n",
    "2. Run the calculation multiple times: Electre Tri in our case\n",
    "3. Obtain a set of results to be analyzed \n",
    "\n",
    "The first step involve to be given Probability Distribution Functions as inputs. For our study, all the values will be represented as normal distributions. To descrive these distributions 2 parameters are needed : \n",
    "- the mean value \n",
    "- the variance\n",
    "\n",
    "*insert an image of a normal distribution showing the mean value & the variance*\n",
    "\n",
    "These values are given in the `d` DataFrame given as input of the code. \n",
    "\n",
    "The following function allows to :\n",
    "1. Thanks to the variance and mean value for each performance : create the Normal Distribution\n",
    "2. Pick a random value in each of it\n",
    "3. Return a DataFrame also called `d` with the random values picked \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "61789852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCarlo(d):\n",
    "    for i in d.index:\n",
    "        variance = d['VAR'][i]\n",
    "        for j in d.iloc[:, 0:28]:\n",
    "            m = d[j][i]\n",
    "            v = abs(m*variance)\n",
    "            perf = random.normal(m, v, 1)\n",
    "            d[j][i] = perf[0]\n",
    "    return d\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "268b5da4",
   "metadata": {},
   "source": [
    "autre version optimisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "e73a5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCarlo(d):\n",
    "    variance = d['VAR'].values\n",
    "    m = d.iloc[:, 0:28].values\n",
    "    v = np.abs(m * variance[:, np.newaxis])\n",
    "    perf = np.random.normal(m, v)\n",
    "    d.iloc[:, 0:28] = perf\n",
    "    return d\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "590af63e",
   "metadata": {},
   "source": [
    "### Concordance\n",
    "\n",
    "The concordance matrix is a table that compare each pair of alternatives being considered, in our case, the sceanarios. In other words, it evaluates how well each option performs relative to the others with respect to the set of criteria. \n",
    "\n",
    "This function take as input the DataFrame containig all the performances as well as all the others parameters and input of the method, but only the performances, the reference profiles, and the thresholds will be used.\n",
    "\n",
    "The objective is to calculate the concordance between each pair of alternative and reference profiles and in both ways: \n",
    "- The concordance $C_j(a_i,b_k)$\n",
    "- The concordance $C_j(a_i,b_k)$ <br>\n",
    "*for $i$ the scenarios, $k$ the reference profiles and $j$ the criteria*\n",
    "\n",
    "Here is how the two types of concordance are calculated in the function: <br>\n",
    "<center>\n",
    "\n",
    "$C_j(a_i,b_k) = uj(a_i)-u_j(b_j)+p_j/p_j-q_j$<br>\n",
    "$C_j(b_k,a_i) = uj(b_j)-u_j(a_i)+p_j/p_j-q_j$<br>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "If the value is higher than one it is replaced by one, and if it is smaller dans zero it is replaced by zero. \n",
    "\n",
    "Finally, the function returns two DataFrames : \n",
    "- `dconca` : The concordance between the performances and the reference profiles $C_k(a_i,b_j)$\n",
    "- `dconcb` : The concordance between the reference profiles and the performances $C_k(a_i,b_j)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0243db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conce2(d):\n",
    "    def calculate_alpha_beta(col1, col2, w, x, y):\n",
    "        alpha = (col1 - col2 + w) / (w - x)\n",
    "        beta = (col2 - col1 + w) / (w - x)\n",
    "        return pd.DataFrame({\"alpha\": alpha.clip(0, 1), \"beta\": beta.clip(0, 1)})\n",
    "\n",
    "    w = d[d.columns[37]]\n",
    "    x = d[d.columns[36]]\n",
    "    y = d.iloc[:,30:36]\n",
    "    alpha_beta = d.iloc[:, 0:28].apply(calculate_alpha_beta, args=(y, w, x, y))\n",
    "    new_df = alpha_beta[\"alpha\"]\n",
    "    new_df2 = alpha_beta[\"beta\"]\n",
    "\n",
    "    return new_df, new_df2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b4c1f41",
   "metadata": {},
   "source": [
    "### Discordance\n",
    "\n",
    "The discordance matrix is a matrix that is used to represent the degree of discordance between pairs of alternatives. It is typically constructed by comparing the values of each alternative on each criterion, and determining whether the difference between the values is significant enough to cause discordance. \n",
    "\n",
    "The objective is to calculate the discordance between each pair of alternative and reference profiles and in both ways: \n",
    "- The discordance $D_j(a_i,b_k)$\n",
    "- The discordance $D_j(b_k,a_i)$ <br>\n",
    "*for $i$ the scenarios, $k$ the reference profiles and $j$ the criteria*\n",
    "\n",
    "Here is how the two types of discordance are calculated in the function: <br>\n",
    "<center>\n",
    "\n",
    "$D_j(a_i,b_k) = uj(b_k)-u_j(a_i)-p_j/v_j-p_j$<br>\n",
    "$D_j(b_k,a_i) = uj(a_i)-u_j(b_k)-p_j/v_j-p_j$<br>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "If the value is higher than one it is replaced by one, and if it is smaller dans zero it is replaced by zero. \n",
    "\n",
    "\n",
    "Finally, the function returns two DataFrames : \n",
    "- `ddiscoa` : The discordance between the performances and the reference profiles $D_j(a_i,b_k)$\n",
    "- `ddiscob` : The discordance between the reference profiles and the performances $D_j(b_k,ba_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "414dda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def disco2(d):\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df2 = pd.DataFrame()\n",
    "    for column in d.iloc[:, 0:28]:\n",
    "        for col in d.iloc[:,30:36]:\n",
    "            alpha = (d[col]-d[column]-d[d.columns[37]])/(d[d.columns[38]]-d[d.columns[37]])\n",
    "            beta = (d[column]-d[col]-d[d.columns[37]])/(d[d.columns[38]]-d[d.columns[37]])\n",
    "            new_df[column+col+' a,b'] = alpha\n",
    "            new_df2[column+col+' b,a'] = beta\n",
    "    new_df[new_df<0]=0\n",
    "    new_df[new_df>1]=1\n",
    "    new_df2[new_df<0]=0\n",
    "    new_df2[new_df>1]=1\n",
    "    return new_df, new_df2\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e896ce2d",
   "metadata": {},
   "source": [
    "### Global concordance\n",
    "\n",
    "The function allows to calculate the global concordance of each scenario regarding each threshold. It takes as input the concordance matrix and the weights for each criteria. <br>\n",
    "*explain what si the global concordance for*\n",
    "\n",
    "The function takes as input the weights of each criterion, located in the `d` DataFrame as well as the concordance matrix, separated into 2 DataFrames previously : `dconca` and `dconcb`. \n",
    "\n",
    "The objective is, for each scenario calculate the following global concordance : \n",
    "\n",
    "<center>\n",
    "\n",
    "$C(a_i,b_k) = \\frac {\\sum_{j} C_j(a_i,b_k) * w_j}{\\sum_{j} w_j}$\n",
    "\n",
    "</center>\n",
    "\n",
    "*with i the scenarios and k the reference profiles*\n",
    "\n",
    "This function has to be used twice :\n",
    "- Once taking as input `dconca` and returning as output `dgconca` : $C(a_i,b_k)$\n",
    "- Once taking as input `dconcb` and returning as output `dgconcb` : $C(b_k,a_i)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aab7fb1f",
   "metadata": {},
   "source": [
    "autre version optimisée je sais pas encore laquelle choisir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f5f4a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_conc(d,dconc1):\n",
    "    new_df = pd.DataFrame(index=['b0', 'b1', 'b2', 'b3', 'b4', 'b5'], columns=['S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1','S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2','S7.3','S7.4']) \n",
    "    cols = dconc1.columns\n",
    "    i = 0\n",
    "    for j in range(0, len(cols),6):\n",
    "        a = sum(dconc1[cols[j]]*d[d.columns[28]])/sum(d[d.columns[28]]) \n",
    "        b = sum(dconc1[cols[j+1]]*d[d.columns[28]])/sum(d[d.columns[28]])  \n",
    "        c = sum(dconc1[cols[j+2]]*d[d.columns[28]])/sum(d[d.columns[28]]) \n",
    "        dr = sum(dconc1[cols[j+3]]*d[d.columns[28]])/sum(d[d.columns[28]])  \n",
    "        e = sum(dconc1[cols[j+4]]*d[d.columns[28]])/sum(d[d.columns[28]]) \n",
    "        f = sum(dconc1[cols[j+5]]*d[d.columns[28]])/sum(d[d.columns[28]]) \n",
    "        th = [a,b,c,dr,e,f]\n",
    "        new_df[new_df.columns[i]]= th\n",
    "        i = i+1\n",
    "    return new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29632769",
   "metadata": {},
   "source": [
    "v2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85cec1c2",
   "metadata": {},
   "source": [
    "### Degree of credibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4f31262",
   "metadata": {},
   "source": [
    "The degree of credibility represents *dire ce que c'est concrètement*\n",
    "\n",
    "The degree of credibility is calculated thanks to :\n",
    "- the global concordance of each scenario with each reference profile $C(a_i,b_k)$ named `dgconca`\n",
    "- the discordance matrix, separated in two DataFrames `ddiscoa` and `ddiscob`\n",
    "\n",
    "The objective is, for each scenario, follow these steps : \n",
    "\n",
    "If for all the criteria $j$,   $D_j(a_i,b_k) \\le C(a_i,b_k)$:\n",
    "<center>\n",
    "\n",
    "$ \\delta(a_i,b_k) = C(a_i,b_k) $\n",
    "\n",
    "</center>\n",
    "\n",
    "Else : \n",
    "\n",
    "<center>\n",
    "\n",
    "$ \\delta(a_i,b_k) = C(a_i,b_k) * \\prod_{j \\in J } \\frac{(1-D_j(a_i,b_k))}{(1-C(a_i,b_k))} $\n",
    "\n",
    "</center>\n",
    "\n",
    "*With J : all the criteria for whom  $D_j(a_i,b_k) \\ge C(a_i,b_k)$*\n",
    "\n",
    "The following function should be run 2 times : \n",
    "- Once considering the comparaison of performance with reference profiles $(a_i,b_k)$\n",
    "    - input : `dgconca` : the global performance  $C(a_i,b_k) $ and `ddiscoa` : the discordance :  $D_j(a_i,b_k) $\n",
    "    - output : `dcreda`: the credibility $ \\delta(a_i,b_k)$ <br>\n",
    "    \n",
    "\n",
    "- Once considering the comparaison of reference profiles with performances $(b_k,a_i)$\n",
    "    - input : `dgconcb` : the global performance  $C(b_k,a_i) $ and `ddiscoa` : the discordance :  $D_j(b_k,a_i) $\n",
    "    - output : `dcredb` the credibility $ \\delta(b_k,a_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "5d1d2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def credibility(dgconca, ddisc):\n",
    "    dcred = dgconca.copy()\n",
    "    cols = ddisc.columns\n",
    "    for j in range(0, len(cols),6):           #pour toutes les colonnes de discordance,toutes les 6 colonnes donc pour chaque scénario\n",
    "        ddiscj = [ddisc[ddisc.columns[j]], ddisc[ddisc.columns[j+1]], ddisc[ddisc.columns[j+2]], ddisc[ddisc.columns[j+3]], ddisc[ddisc.columns[j+4]], ddisc[ddisc.columns[j+5]]].copy()\n",
    "        cglobal = [dgconca[dgconca.columns[j/6]][0], dgconca[dgconca.columns[j/6]][1],dgconca[dgconca.columns[j/6]][2], dgconca[dgconca.columns[j/6]][3], dgconca[dgconca.columns[j/6]][4], dgconca[dgconca.columns[j/6]][5]]\n",
    "        dc = [0, 0, 0, 0, 0, 0]\n",
    "        for i in range(len(cglobal)):        #pour chaque profil de référence\n",
    "            verif = 0\n",
    "            for c in ddisc.index:           #parcours les valeurs de la colonne\n",
    "                if  ddisc[cols[j+i]][c] > cglobal[i]:           #si une valeur de la colonne est supérieur au coef de concordance global \n",
    "                    verif = verif + 1\n",
    "            if verif == 0 :\n",
    "                dc[i] = cglobal[i]\n",
    "            else: \n",
    "                df_mask = ddiscj[i]>cglobal[i] \n",
    "                filtered_ddisc = ddisc[df_mask]\n",
    "                degree = (((1-filtered_ddisc[cols[j+i]])/(1-cglobal[i])).prod())*cglobal[i] #le degré de credibilité du profil i et du scénario j\n",
    "        dcred[dcred.columns[j/6]] = dc\n",
    "    return dcred\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c8d87cf",
   "metadata": {},
   "source": [
    "### Over Ranking\n",
    "\n",
    "The objective of this step is to establish preference relationships between performance and reference profiles. \n",
    "These relationships are established than the degree  of credibility determined just before and thanks to the cutting threshold $\\lambda$. \n",
    "The value of this cutting threshold can vary, and it value will be discussed later. \n",
    "\n",
    "There are 4 types of relationships that can be established between each $a_i$ and each $b_k$\n",
    "- $a_i$  `I`  $b_k$ : $a_i$  is Indifferent to  $b_k$ \n",
    "- $a_i$  `>`  $b_k$ : $a_i$  is prefered to  $b_k$ \n",
    "- $a_i$  `<`  $b_k$ : $a_i$  is not prefered to  $b_k$ \n",
    "- $a_i$  `R`  $b_k$ : $a_i$  uncomparable to $b_k$ \n",
    "\n",
    "This is how this these relationship are determined : \n",
    "\n",
    "![](my_image.jpeg)\n",
    "\n",
    "*insérer le tableau*\n",
    "\n",
    "The function will return a Dataframe `dranking` containing all these relations between performance and reference profiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f04613ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_ranking_relations(creda, credb, λ):\n",
    "    new_df = creda.copy()\n",
    "    classementa = creda.apply(lambda x: x-λ)\n",
    "    classementb = credb.apply(lambda x: x-λ)\n",
    "    classementa[classementa > 0] = 1  # surclasse\n",
    "    classementa[classementa < 0] = 0  # ne surclasse pas\n",
    "    classementb[classementb > 0] = 1\n",
    "    classementb[classementb < 0] = 0\n",
    "    mask = (classementa == classementb) & (classementa == 1)\n",
    "    new_df = new_df.mask(mask, \"I\")\n",
    "    mask = (classementa == classementb) & (classementa == 0)\n",
    "    new_df = new_df.mask(mask, \"R\")\n",
    "    mask = (classementb != 0) & (classementa == 0)\n",
    "    new_df = new_df.mask(mask, \"<\")\n",
    "    mask = (classementa != 0) & (classementb == 0)\n",
    "    new_df = new_df.mask(mask, \">\")\n",
    "    return new_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2e4b611",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "The objective of the whole method is to obtain a ranking of the multiple alternatives we have for our problem. \n",
    "This method gives two types of rankings : *the pessimistic ranking and the optimistic ranking.*\n",
    "\n",
    "A median ranking can be obtained as an average of these two rankings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07cc33b8",
   "metadata": {},
   "source": [
    "### Pessimistic sorting\n",
    "\n",
    "The following function permits to obtain the pessimistic ranking thanks to the over ranking relationships we just established.\n",
    "\n",
    "This is how the ranking works : <br>\n",
    "\n",
    "The 6 reference profiles $b0, b1, b2, b3, b4$ and $b5$ delineate 5 categories : <br>\n",
    "$C1, C2, C3, C4$ and $C5$, C5 being the best one and C1 the worse : \n",
    "\n",
    "*insert image of pessimistic ranking*\n",
    "\n",
    "For each scenario, these categories will be browsed from the best to the worst ( from C5 to C1 ). \n",
    "For each reference profiles encountered the credibility $ \\delta(a_i,b_k)$ will be compared to the cutting threshold $\\lambda$ : \n",
    "- if $ \\delta(a_i,b_k) > \\lambda $ : the scenario is ranked in the category with the same number as $b_k$\n",
    "- if $ \\delta(a_i,b_k) < \\lambda $ : we continue to the next reference profile \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "0c83fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pessimistic_sort(dov,new_df):\n",
    "    # transpose the DataFrame so that the rows become columns\n",
    "    #stop_rows = []  # store the index of the row where the loop stopped for each column\n",
    "    cat = new_df.index\n",
    "    for col in dov: #pour le scéénario col  \n",
    "        etape = new_df[col] \n",
    "        print(col)\n",
    "        for j in reversed(range(len(dov.index))): \n",
    "            if dov[col][j] == '>' or dov[col][j] == 'I':\n",
    "                etape[etape.index[j]] = etape[etape.index[j]] +1\n",
    "                #new_df[col][new_df.index[j]] = new_df[col][new_df.index[j]]+1\n",
    "                break\n",
    "        new_df[col] = etape\n",
    "        print(new_df[col])\n",
    "    return new_df #, stop_rows\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4da92d51",
   "metadata": {},
   "source": [
    "### Optimistic sorting\n",
    "\n",
    "The following function permits to obtain the optimistic ranking thanks to the over ranking relationships we just established.\n",
    "\n",
    "This is how the ranking works : <br>\n",
    "\n",
    "As previously 6 reference profiles delineate 5 categories, C5 being the best one and C1 the worse : \n",
    "\n",
    "*insert image of pessimistic ranking*\n",
    "\n",
    "The difference is that for this ranking, for each scenario, these categories will be browsed from the worst to the best ( from C1 to C5 ). \n",
    "For each reference profiles encountered the over ranking relation will be analyzed : \n",
    "- if $a_i$ `<` $b_k$ : the scenario is ranked in the category with the same number as $b_k$\n",
    "- if $a_i$ `>` $b_k$, $a_i$ `R` $b_k$ or $a_i$ `I` $b_k$ : we continue to the next reference profile \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "f5de8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimistic_sort(dov,new_df):\n",
    "    # transpose the DataFrame so that the rows become columns\n",
    "    #stop_rows = []  # store the index of the row where the loop stopped for each colum\n",
    "    cat = new_df.index\n",
    "    for col in dov: \n",
    "        etape = new_df[col] \n",
    "        for j in range(len(dov.index)): \n",
    "            if dov[col][j] == '<' or dov[col][j] == 'R':\n",
    "                etape[etape.index[j-1]] = etape[etape.index[j-1]] +1\n",
    "                break\n",
    "        new_df[col] = etape \n",
    "        print(new_df[col])\n",
    "    return new_df #, stop_rows\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "849eec95",
   "metadata": {},
   "source": [
    "### Electre Tri method\n",
    "\n",
    "This final method permits to run all the previous methods in order to compute all the steps of the Electre Tri method. \n",
    "It takes as input : \n",
    "- `d` : the input Dataframe containing the performances, the weights, the variance, the reference profiles and the thresholds\n",
    "- `rep` : the number of times we want the method to be executed\n",
    "\n",
    "It will return a csv file containing the repartition of the scenarios in the categories as percentages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "fd90570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def electre_tri (d,rep):\n",
    "    temp = np.zeros((5,28))\n",
    "    pessi_sort = pd.DataFrame(temp, index=['C1', 'C2', 'C3', 'C4', 'C5'], columns=['S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1','S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2','S7.3','S7.4'])\n",
    "    opti_sort = pd.DataFrame(temp, index=['C1', 'C2', 'C3', 'C4', 'C5'], columns=['S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1','S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2','S7.3','S7.4'])\n",
    "    for i in range(rep) :\n",
    "        print(i)\n",
    "        d = MCarlo(d)\n",
    "        dconca, dconcb = conce2(d)\n",
    "        ddisca, ddiscb = disco2(d)\n",
    "        dgconca = global_conc(d,dconca)\n",
    "        dgconcb = global_conc(d,dconcb)\n",
    "        dcreda = credibility(dgconca, ddisca)\n",
    "        dcredb = credibility(dgconcb, ddiscb)\n",
    "        dranking = over_ranking_relations(dcreda, dcredb, λ)\n",
    "        print(dranking)\n",
    "        pessi_sort = pessimistic_sort(dranking,pessi_sort)\n",
    "        opti_sort = optimistic_sort(dranking,opti_sort)\n",
    "        print(pessi_sort)\n",
    "        print(opti_sort)\n",
    "    return opti_sort, pessi_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "24b6f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def electre_tri2 (d):\n",
    "    temp = np.zeros((5,28))\n",
    "    pessi_sort = pd.DataFrame(temp, index=['C1', 'C2', 'C3', 'C4', 'C5'], columns=['S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1','S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2','S7.3','S7.4'])\n",
    "    opti_sort = pd.DataFrame(temp, index=['C1', 'C2', 'C3', 'C4', 'C5'], columns=['S1.1','S1.2','S1.3','S1.4','S2.1','S2.2','S2.3','S2.4','S3.1','S3.2','S3.3','S3.4','S4.1','S4.2','S4.3','S4.4','S5.1','S5.2','S5.3','S5.4','S6.1','S6.2','S6.3','S6.4','S7.1','S7.2','S7.3','S7.4'])\n",
    "    d = MCarlo(d)\n",
    "    dconca, dconcb = conce2(d)\n",
    "    ddisca, ddiscb = disco2(d)\n",
    "    dgconca = global_conc(d,dconca)\n",
    "    dgconcb = global_conc(d,dconcb)\n",
    "    dcreda = credibility(dgconca, ddisca)\n",
    "    dcredb = credibility(dgconcb, ddiscb)\n",
    "    dranking = over_ranking_relations(dcreda, dcredb, λ)\n",
    "    pessi_sort = pessimistic_sort(dranking,pessi_sort)\n",
    "    print(pessi_sort)\n",
    "    opti_sort = optimistic_sort(dranking,opti_sort)\n",
    "    print(opti_sort)\n",
    "    return opti_sort, pessi_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "b3f57cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\roxan\\OneDrive\\Documents\\GitHub\\PIRD\\Code221201 Roxane main.ipynb Cellule 33\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m repet \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m opti_sort, pessi_sort \u001b[39m=\u001b[39m electre_tri (d, repet)\n",
      "\u001b[1;32mc:\\Users\\roxan\\OneDrive\\Documents\\GitHub\\PIRD\\Code221201 Roxane main.ipynb Cellule 33\u001b[0m in \u001b[0;36melectre_tri\u001b[1;34m(d, rep)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(i)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m d \u001b[39m=\u001b[39m MCarlo(d)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m dconca, dconcb \u001b[39m=\u001b[39m conce2(d)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m ddisca, ddiscb \u001b[39m=\u001b[39m disco2(d)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m dgconca \u001b[39m=\u001b[39m global_conc(d,dconca)\n",
      "\u001b[1;32mc:\\Users\\roxan\\OneDrive\\Documents\\GitHub\\PIRD\\Code221201 Roxane main.ipynb Cellule 33\u001b[0m in \u001b[0;36mconce2\u001b[1;34m(d)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x \u001b[39m=\u001b[39m d[d\u001b[39m.\u001b[39mcolumns[\u001b[39m36\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m y \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39miloc[:,\u001b[39m30\u001b[39m:\u001b[39m36\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m alpha_beta \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39;49miloc[:, \u001b[39m0\u001b[39;49m:\u001b[39m28\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(calculate_alpha_beta, args\u001b[39m=\u001b[39;49m(y, w, x, y))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m new_df \u001b[39m=\u001b[39m alpha_beta[\u001b[39m\"\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m new_df2 \u001b[39m=\u001b[39m alpha_beta[\u001b[39m\"\u001b[39m\u001b[39mbeta\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\roxan\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:8839\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8828\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   8830\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   8831\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   8832\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8837\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   8838\u001b[0m )\n\u001b[1;32m-> 8839\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\roxan\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:727\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    725\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 727\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\roxan\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:851\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    853\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\roxan\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:867\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    865\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    866\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    868\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    869\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    870\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    871\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\roxan\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:138\u001b[0m, in \u001b[0;36mApply.__init__.<locals>.f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\roxan\\OneDrive\\Documents\\GitHub\\PIRD\\Code221201 Roxane main.ipynb Cellule 33\u001b[0m in \u001b[0;36mconce2.<locals>.calculate_alpha_beta\u001b[1;34m(col1, col2, w, x, y)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m alpha \u001b[39m=\u001b[39m (col1 \u001b[39m-\u001b[39m col2 \u001b[39m+\u001b[39m w) \u001b[39m/\u001b[39m (w \u001b[39m-\u001b[39m x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m beta \u001b[39m=\u001b[39m (col2 \u001b[39m-\u001b[39m col1 \u001b[39m+\u001b[39m w) \u001b[39m/\u001b[39m (w \u001b[39m-\u001b[39m x)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/roxan/OneDrive/Documents/GitHub/PIRD/Code221201%20Roxane%20main.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m\"\u001b[39;49m\u001b[39malpha\u001b[39;49m\u001b[39m\"\u001b[39;49m: alpha\u001b[39m.\u001b[39;49mclip(\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mbeta\u001b[39;49m\u001b[39m\"\u001b[39;49m: beta\u001b[39m.\u001b[39;49mclip(\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)})\n",
      "File \u001b[1;32mc:\\Users\\roxan\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    637\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\roxan\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[39m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[39melse\u001b[39;00m x\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[39m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\roxan\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    121\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\roxan\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    663\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m indexes \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 664\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf using all scalar values, you must pass an index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[39melif\u001b[39;00m have_series:\n\u001b[0;32m    667\u001b[0m     index \u001b[39m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "repet = 1\n",
    "opti_sort, pessi_sort = electre_tri (d, repet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c7b84",
   "metadata": {},
   "source": [
    "Ici je pense on peut garder car prends directement les infos des csv mais prendre avec panda et pas faire \"append\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b6de171f94b0913ceedb8ce2edb5da18dca4a22bcb75081cdf1074cbb37c4f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
